{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación II\n",
    "\n",
    "Evaluación de contenidos 2 Módulo 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenidas a una nueva evaluación del Bootcamp de Análisis de Datos de Adalab.\n",
    "Como en evaluaciones anteriores dispondréis de 2 tardes (aproximadamente 8 horas para la resolución de todos los ejercicios propuestos).\n",
    "\n",
    "\n",
    "Estos ejercicios se tendrán que defender en el día de la evaluación de forma individual con vuestra tutora docente en una simulación de entrevista técnica donde tendréis de 20 minutos para resolver o explicar los ejercicios propuestos entregados.\n",
    "\n",
    "\n",
    "En esta evaluación nos enfrentamos a un desafío emocionante de trabajar en un proyecto real para una empresa que realiza un estudio de universidades por el mundo. El proyecto tiene como objetivo identificar todas las universidades ubicadas en tres países específicos: Estados Unidos, Canadá y Argentina.\n",
    "\n",
    "\n",
    "Para llevar a cabo esta tarea, utilizaremos la API de \"Universities Hipolabs\", una fuente confiable y completa de información sobre las universidades en todo el mundo. Con la ayuda de esta API, podemos acceder a una gran cantidad de datos relevantes, incluyendo el nombre de la universidad, la ciudad donde esta ubicada, el nombre de la institución y otra información importante que nos permitirá llevar a cabo un análisis detallado.\n",
    "\n",
    "Es importante tener en cuenta que este proyecto requerirá un conocimiento profundo de herramientas y técnicas de análisis de datos, así como habilidades en programación y manejo de APIs. \n",
    "También es importante tener una comprensión sólida de la estructura y organización de los datos, ya que esto nos permitirá hacer preguntas importantes y obtener respuestas significativas a partir de los datos.\n",
    "\n",
    "\n",
    "En resumen, esta prueba técnica ofrece una excelente oportunidad para demostrar habilidades y conocimientos en análisis de datos y programación, mientras se trabaja en un proyecto real y relevante para una empresa. Al finalizar del proyecto, esperamos obtener información valiosa que ayudará a la empresa a tomar decisiones más informadas sobre las universidades en los tres países objetivo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA DE LA ALUMNA:\n",
    "*Los comentarios sobre el código se incluyen en cursiva durante el ejercicio*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "Utilizando la API extraed toda la información que podáis de ella. La url para hacer las llamadas es:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preparamos una constante que usaremos en diferentes llamadas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://universities.hipolabs.com/search?country=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent='geo')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usamos la API para obtener los datos de Canadá, Estados Unidos y Argentina*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get(url= API_URL + 'Canada')\n",
    "\n",
    "df_uni = pd.json_normalize(response.json())\n",
    "\n",
    "response = requests.get(url= API_URL + 'United States')\n",
    "\n",
    "df_uni = pd.concat([df_uni, pd.json_normalize(response.json())] )\n",
    "\n",
    "response = requests.get(url= API_URL + 'Argentina')\n",
    "\n",
    "df_uni = pd.concat([df_uni, pd.json_normalize(response.json())] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Una vez tengáis todos los datos de la API, deberéis realizar una serie de procesos de limpieza, estos incluyen:\n",
    "\n",
    "> Cambiad los nombres de las columnas para homogeneizarlas, tenemos columnas que tienen - y otras _. Unifícalo para que todo vaya con _.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creamos una dictionary comprehension que contenga los cambios a realizar a las columnas y la igualamos a una variable.* \n",
    "\n",
    "*Usamos el método rename sobre el dataframe, igualando columns a la variable que contiene el diccionario con los cambios. Debemos incluir el inplace = True para que nos sobreescriba el dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_columnas = {col: col.replace(\"-\", \"_\").lower() for col in df_uni.columns}\n",
    "df_uni.rename(columns = nuevas_columnas, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> La columna de domains nos da una información similar a la de web_pages. Eliminad la columna domains."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usamos el método drop sobre la columna domains, especificando el axis =1, las columnas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = df_uni.drop('domains', axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Si exploramos la columna de web_pages, nos daremos cuenta que hay universidades, como por ejemplo la Universidad de \"Cégep de Saint-Jérôme\" de Canadá que en su columna de web_pages tiene más de un valor dentro de la lista. \n",
    "\n",
    "Esto es poco práctico y puede llegar a no tener sentido. El objetivo de este ejericio es que usando el método explode de pandas separéis cada elemento de la lista en una fila nueva. Tenéis la documentación de este método.\n",
    "Al final os quedará una tabla similar a la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_province</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>Cégep de Saint-Jérôme</td>\n",
       "      <td>Canada</td>\n",
       "      <td>https://www.cstj.qc.ca</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>Cégep de Saint-Jérôme</td>\n",
       "      <td>Canada</td>\n",
       "      <td>https://ccmt.cstj.qc.ca</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>Cégep de Saint-Jérôme</td>\n",
       "      <td>Canada</td>\n",
       "      <td>https://ccml.cstj.qc.ca</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Lambton College</td>\n",
       "      <td>Canada</td>\n",
       "      <td>https://www.lambtoncollege.ca</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Acadia University</td>\n",
       "      <td>Canada</td>\n",
       "      <td>http://www.acadiau.ca/</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Nacional de Tres de Febrero</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.untref.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Universidad Torcuato di Tella</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.utdt.edu/</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Universidad Tecnológica Nacional</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.utn.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>Universidad Abierta Interamericana</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.vaneduc.edu.ar/uai/</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>Universidad Nacional de Villa María</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://webs.satlink.com/usuarios/i/iiunvm/</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2535 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     state_province                                     name  \\\n",
       "0                            Quebec                    Cégep de Saint-Jérôme   \n",
       "0                            Quebec                    Cégep de Saint-Jérôme   \n",
       "0                            Quebec                    Cégep de Saint-Jérôme   \n",
       "1                           Ontario                          Lambton College   \n",
       "2                       Nova Scotia                        Acadia University   \n",
       "..                              ...                                      ...   \n",
       "82                     Buenos Aires  Universidad Nacional de Tres de Febrero   \n",
       "83  Ciudad Autónoma de Buenos Aires            Universidad Torcuato di Tella   \n",
       "84  Ciudad Autónoma de Buenos Aires         Universidad Tecnológica Nacional   \n",
       "85  Ciudad Autónoma de Buenos Aires       Universidad Abierta Interamericana   \n",
       "86                             None      Universidad Nacional de Villa María   \n",
       "\n",
       "      country                                   web_pages alpha_two_code  \n",
       "0      Canada                      https://www.cstj.qc.ca             CA  \n",
       "0      Canada                     https://ccmt.cstj.qc.ca             CA  \n",
       "0      Canada                     https://ccml.cstj.qc.ca             CA  \n",
       "1      Canada               https://www.lambtoncollege.ca             CA  \n",
       "2      Canada                      http://www.acadiau.ca/             CA  \n",
       "..        ...                                         ...            ...  \n",
       "82  Argentina                   http://www.untref.edu.ar/             AR  \n",
       "83  Argentina                        http://www.utdt.edu/             AR  \n",
       "84  Argentina                      http://www.utn.edu.ar/             AR  \n",
       "85  Argentina              http://www.vaneduc.edu.ar/uai/             AR  \n",
       "86  Argentina  http://webs.satlink.com/usuarios/i/iiunvm/             AR  \n",
       "\n",
       "[2535 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uni.explode('web_pages')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Una vez hayáis realizado el explode, chequead si tenéis duplicados basándonos unicamente en el nombre de la universidad, en caso de que si, eliminandlos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usando el método drop_duplicates eliminaremos los duplicados existentes en la columna 'name'.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni.drop_duplicates(subset = ['name'], inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Si exploramos la columna de state_province veremos que hay universidades cuyo valor para esta columna es None. Cread una función para reemplazar los None por nulos de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uni['state_province'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni['state_province'].fillna(np.NaN, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Después del último cambio, os habréis dado cuenta que tenemos muchos valores nulos dentro de la columna de state_province, por lo que nuestro jefe nos pide que reemplacemos esos nulos por \"Unknown\". \n",
    "\n",
    "No nos piden ningún método especifico, así que podremos usar el método que queramos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Usamos el método .fillna() sobre la columna 'state_province' con inplace = True para sobre escribir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni['state_province'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Ahora nuestros jefes nos piden que saquemos las coordenadas de las provincias donde están ubicadas las universidades. Para eso nos piden que usemos la librería de geopy que aprendimos el día del repaso,  la documentación. Para desarrollar este ejercicio deberéis:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Sacar los valores únicos de la columna state_province.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Quebec', 'Ontario', 'Nova Scotia', 'British Columbia', 'Alberta',\n",
       "       'Manitoba', 'New Brunswick', 'Saskatchewan', 'Unknown',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Pennsylvania', 'NV', 'Iowa', 'VA', 'TX', 'Colorado', 'IN', 'CA',\n",
       "       'South Carolina', 'Washington', 'NY', 'Texas', 'ND', 'MI', 'Ohio',\n",
       "       'Florida', 'California', 'North Carolina', 'Michigan', 'GA',\n",
       "       'New York, NY', 'Buenos Aires', 'Ciudad Autónoma de Buenos Aires',\n",
       "       'Entre Ríos', 'Salta', 'Córdoba', 'Mendoza', 'Santa Fé',\n",
       "       'Santiago Del Estero', 'Misiones', 'Catamarca', 'Formosa', 'Jujuy',\n",
       "       'La Rioja', 'La Pampa', 'San Juan', 'San Luis', 'Tucumán'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uni['state_province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_states = {\n",
    "    'NV':'Nevada', \n",
    "    'TX':'Texas',\n",
    "    'IN':'Indianapolis',\n",
    "    'CA':'California',\n",
    "    'VA':'Virginia',\n",
    "    'NY':'New York',\n",
    "    'MI':'Michigan',\n",
    "    'GA':'Georgia',\n",
    "    'ND':'North Dakota',\n",
    "    'New York, NY': 'New York',\n",
    "    'Ciudad Autónoma de Buenos Aires': 'Buenos Aires'}\n",
    "\n",
    "df_uni['state_province'].replace(new_states, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Quebec', 'Ontario', 'Nova Scotia', 'British Columbia', 'Alberta',\n",
       "       'Manitoba', 'New Brunswick', 'Saskatchewan', 'Unknown',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Pennsylvania', 'Nevada', 'Iowa', 'Virginia', 'Texas', 'Colorado',\n",
       "       'Indianapolis', 'California', 'South Carolina', 'Washington',\n",
       "       'New York', 'North Dakota', 'Michigan', 'Ohio', 'Florida',\n",
       "       'North Carolina', 'Georgia', 'Buenos Aires', 'Entre Ríos', 'Salta',\n",
       "       'Córdoba', 'Mendoza', 'Santa Fé', 'Santiago Del Estero',\n",
       "       'Misiones', 'Catamarca', 'Formosa', 'Jujuy', 'La Rioja',\n",
       "       'La Pampa', 'San Juan', 'San Luis', 'Tucumán'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uni['state_province'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Algunos de los valores que tenemos están con siglas, y deberéis reemplazarlos por lo siguiente:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> NV: reemplazalo por Nevada\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">TX: reemplazalo por Texas\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">IN: reemplazalo por Indianapolis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">CA: reemplazalo por California\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">VA: reemplazalo por Virginia\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">NY: reemplazalo por New York\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">MI: reemplazalo por Michigan\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">GA: reemplazalo por Georgia\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ND: reemplazalo por North Dakota\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Otros valores que tenemos más formateados son y que deberemos reemplazar:\n",
    "\n",
    ">New York, NY. Deberéis reemplazarlo por \"New York\".\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'Buenos Aires', 'Ciudad Autónoma de Buenos Aires'. En este caso deberéis poner en ambos casos \"Buenos Aires\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Una vez realizados los pasos anteriores, crea una lista con los valores únicos de las provincias de las universidades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quebec',\n",
       " 'Ontario',\n",
       " 'Nova Scotia',\n",
       " 'British Columbia',\n",
       " 'Alberta',\n",
       " 'Manitoba',\n",
       " 'New Brunswick',\n",
       " 'Saskatchewan',\n",
       " 'Unknown',\n",
       " 'Newfoundland and Labrador',\n",
       " 'Prince Edward Island',\n",
       " 'Yukon',\n",
       " 'Pennsylvania',\n",
       " 'Nevada',\n",
       " 'Iowa',\n",
       " 'Virginia',\n",
       " 'Texas',\n",
       " 'Colorado',\n",
       " 'Indianapolis',\n",
       " 'California',\n",
       " 'South Carolina',\n",
       " 'Washington',\n",
       " 'New York',\n",
       " 'North Dakota',\n",
       " 'Michigan',\n",
       " 'Ohio',\n",
       " 'Florida',\n",
       " 'North Carolina',\n",
       " 'Georgia',\n",
       " 'Buenos Aires',\n",
       " 'Entre Ríos',\n",
       " 'Salta',\n",
       " 'Córdoba',\n",
       " 'Mendoza',\n",
       " 'Santa Fé',\n",
       " 'Santiago Del Estero',\n",
       " 'Misiones',\n",
       " 'Catamarca',\n",
       " 'Formosa',\n",
       " 'Jujuy',\n",
       " 'La Rioja',\n",
       " 'La Pampa',\n",
       " 'San Juan',\n",
       " 'San Luis',\n",
       " 'Tucumán']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_list = df_uni['state_province'].unique().tolist()\n",
    "\n",
    "states_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Usando la API de geopy, extraed la latitud y la longitud de cada una de las provincias y almacenad los resultados en un dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.3.0-py3-none-any.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting geographiclib<3,>=1.52\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 6.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quebec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nova Scotia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alberta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              state\n",
       "0            Quebec\n",
       "1           Ontario\n",
       "2       Nova Scotia\n",
       "3  British Columbia\n",
       "4           Alberta"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo = pd.DataFrame(states_list, columns= ['state'])\n",
    "df_geo.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_geo.iterrows():\n",
    "    location = geolocator.geocode(row['state'])\n",
    "    df_geo.at[i, 'latitude'] = location.latitude\n",
    "    df_geo.at[i, 'longitude'] = location.longitude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Una vez que tengáis los datos del ejercicio anterior en un dataframe, unidlo con el de las universidades que hemos sacado de la API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/20375561/joining-pandas-dataframes-by-column-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = df_uni.merge(df_geo, left_on = 'state_province', right_on = 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = df_uni.drop('state', axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Crea una BBDD en mysql que contenga las siguientes tablas:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Este ejercicio se encuentra en una carpeta llamada anexo*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Introduce todo el código que habéis ido creando en funciones, siguiendo la misma lógica que hemos seguido en los pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Este ejercicio se presenta en un archivo extra llamado funciones*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e93b45245d013bdd53ec1af459c1fa9a1f27ba233da755697f4231c0d29b83f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
